{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319d7569-c5d1-4477-b255-db416f7208dd",
   "metadata": {},
   "source": [
    "# Introduction to Computer Vision and OpenCV:\n",
    "\n",
    "Understand the fundamentals of computer vision and its applications.\n",
    "Learn the basics of the OpenCV library and its core functions.\n",
    "Setup your development environment with OpenCv\n",
    "Load and display images using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e309267-8895-4e66-b49c-2cdb71b51633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e04c9dab-5a2e-411f-9ed0-7d324da66bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/work/Desktop/ccp-cv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1359ca07-4bc1-4c8e-a6fc-da3f68fe0974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48763fc5-32e8-4e79-8232-cff390e79b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./cat.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50947836-0952-43c5-a30b-d29a0208cb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436fec87-80b3-4aa1-aa22-8c891e019b1c",
   "metadata": {},
   "source": [
    "# Image Processing Techniques using OpenCV:\n",
    "\n",
    "Implement basic image processing techniques such as resizing, cropping, and color manipulation.\n",
    "Apply various filters and enhancements to images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e26d721-7b82-4051-928e-ac7362d4692c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cord = 0\n",
    "y_cord = 0\n",
    "\n",
    "def mouse_callback(event, x, y, flats, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(img, (x,y), radius=3, color=(0, 0, 255), thickness=2)\n",
    "        cv2.putText(img, f'x:{x}', (x+10,y-10) , \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.5, \n",
    "                    (0,0,0), 2)\n",
    "        cv2.putText(img, f'y:{y}', (x+10,y+10) , \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    (0,0,0), 2)\n",
    "        cv2.imshow('Image', img)\n",
    "        print(f\"Coordinates: {x}, {y}\")\n",
    "\n",
    "# Create a window and set the mouse callback function\n",
    "cv2.namedWindow('Image')\n",
    "cv2.setMouseCallback('Image', mouse_callback)\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ab6b931-1a53-4249-93b2-3fbb8fd371db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(imgs):\n",
    "    for k, img in imgs.items():\n",
    "        cv2.imshow(k, img)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e2a9a80-2b33-4562-ba91-84ea3ed59056",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_face = img[18:356, 103:416]\n",
    "resized = cv2.resize(img, (100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6512853-8a60-4371-9688-81bc82fe5648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('img', resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "842ff086-d5d8-4914-8c5f-8cf9a113ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_img = cv2.GaussianBlur(img, (9,9), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9311e960-f61b-46f4-ba4d-3d24ff93ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af61cddc-5316-424a-977c-8399451a324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f81bbed1-349a-45f0-b071-513014bdc76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, otsu_thresholding = cv2.threshold(img_gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dac56bb3-9fd5-4925-9b56-d73fe3aea660",
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(img_gray,50,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57192c6f-8132-4ee1-a617-21718b5d45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "opening = cv2.morphologyEx(otsu_thresholding, cv2.MORPH_OPEN, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d20388ce-060f-4d4a-bf46-c8f82f6bdf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_img = 255 - img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9352cfe-a7e6-44ec-a4a1-835df4fabc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'opening':opening,\n",
    "          'otsu_thresholding':otsu_thresholding,\n",
    "          'Gaussian':blurred_img,\n",
    "          'invert':inverted_img})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7bcc8-f688-4095-9baa-1af0b125b298",
   "metadata": {},
   "source": [
    "# Object Detection and Tracking:\n",
    "\n",
    "Implement object detection using pre-trained deep learning models (e.g., YOLO or SSD).\n",
    "Develop real-time object tracking using techniques like the Kalman filter or Mean-Shift algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02cea03b-4ccb-491e-a8b5-1ac0a2f1a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load YOLO model\n",
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
    "img = cv2.imread('./cat.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78def8ed-9088-44e8-8eb1-8273d4515f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cv2.resize(img, (416,416))\n",
    "\n",
    "scalefactor = 1.0/255.0\n",
    "size = (416,416)\n",
    "mean = (0,0) # Mean values for image Normalisation\n",
    "swapRB = True # Swap red and blue channels for image preprocessing\n",
    "crop = False # Do not crop the image during blob creation\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(resized,\n",
    "                            scalefactor,\n",
    "                            size,\n",
    "                            mean,\n",
    "                            swapRB=swapRB,\n",
    "                            crop=crop)\n",
    "\n",
    "net.setInput(blob)\n",
    "output_layers = net.getUnconnectedOutLayersNames()\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "# tracker = cv2.TrackerKCF_create()\n",
    "tracker = cv2.legacy_TrackerMOSSE.create()\n",
    "\n",
    "bbox = cv2.selectROI(img, False)\n",
    "\n",
    "tracker.init(img, bbox)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be07e5f-391c-42c5-8926-68487c46abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b593d5e2-c763-4739-b318-1f4d2db4f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':resized})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4874a0d9-04a2-427a-9f3c-b6d1ad6deeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b6a440-4df8-4b37-af98-e1aa62788ed7",
   "metadata": {},
   "source": [
    "# Feature Detection and Matching:\n",
    "\n",
    "Explore feature detection methods such as SIFT or ORB.\n",
    "Implement feature matching to establish correspondence between images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff335229-899e-4014-9227-f414f20ea2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread('./cat.jpg')\n",
    "img2 = cv2.imread('./cat2.jpg')\n",
    "\n",
    "# Create a ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Find key Points and descriptors\n",
    "keypoints1, descriptors1 = orb.detectAndCompute(img1, None)\n",
    "keypoints2, descriptors2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "# Initialize Brute force matcher\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# Match Descriptors \n",
    "matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "matching_results = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches[:30], None, flags=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9768ea80-92d2-4eff-a5c0-68b0c740c92b",
   "metadata": {},
   "source": [
    "* im1 - The source image\n",
    "* keypoints1 - list of key points detected in the first image\n",
    "* im2 - second image where matches will be viualized\n",
    "* keypoints2 - List of keypoints detected in second image\n",
    "* matches[:20] - a subset of matches to be draw\n",
    "* None - Optional mask image, if provided, only the key points that are within the mask will be used in the matching visualisation \n",
    "* flats = 2 - the flag that specifies how to draw the matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0feef99c-f2ed-4bc2-95e3-c8f05ce898b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':matching_results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "071221b9-0815-4b3b-8658-3d031583e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':descriptors2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677148e3-9ef4-4c2e-9773-0a6cf0fc3526",
   "metadata": {},
   "source": [
    "# Activity 5: Image Filtering and Transformation:\n",
    "\n",
    " Apply advanced image filtering techniques, such as Gaussian blur and edge detection.\n",
    " Explore geometric transformations like rotation, scaling, and perspective transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fc7e7cd-b353-4752-9688-aee1596fb4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = cv2.GaussianBlur(img1, (11,11), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be147f6f-e65e-4305-8be1-72ad2234636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb2934fa-229f-40ba-8218-b04c3499149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(gray,100,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "feccdc09-ef2b-4fea-9b3d-03a8d53a9883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation\n",
    "angle = 30\n",
    "rows, cols = img1.shape[:2]\n",
    "rotation_matrix = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
    "rotated_matrix = cv2.warpAffine(img1, rotation_matrix, (cols, rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbc0244a-31b4-4da3-812d-ca163849cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':gaussian,\n",
    "          'cann':edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c3cd12a-643c-4f65-a788-ffcb839a5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':rotated_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92df741c-4e9f-435a-9b29-362c1955d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = 0.5\n",
    "scaled = cv2.resize(img1, None, fx=scale_factor, fy=scale_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c865097e-425a-4b22-b27b-91c287f0b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':scaled})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "040c5d46-8505-4cd4-b2b9-5b6c6616a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspective transformation\n",
    "pts1 = np.float32([[50,50], [200,50], [50, 200], [200, 200]])\n",
    "pts2 = np.float32([[0,0], [250,0], [0, 250], [250, 250]])\n",
    "\n",
    "perspective_matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "perspective_transformed = cv2.warpPerspective(img1, perspective_matrix, (250,250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f1ebf3b4-fe3c-455b-ae15-d4c8090a183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':perspective_transformed})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4361ff-2081-4cb5-a025-f67360a4848c",
   "metadata": {},
   "source": [
    "# Activity 6: Advanced Computer Vision Techniques:\n",
    " Dive into advanced techniques like image segmentation and contour detection.\n",
    "\n",
    " Implement optical flow for motion analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9198f26a-84a1-4be0-bab8-7f0f4a887c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('cat.jpg', )\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a015f64-67ee-4d72-bc6e-4b844f455fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(gray, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4b2cd483-c3fb-47af-ad4f-b3f810c7e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "453320e9-5934-4076-98a8-131c1299dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_images = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bbb289aa-4b50-4c12-a3af-0bead156b8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 39,  69,  34],\n",
       "        [ 38,  69,  32],\n",
       "        [ 37,  68,  31],\n",
       "        ...,\n",
       "        [ 39,  90,  40],\n",
       "        [ 41,  91,  43],\n",
       "        [ 43,  93,  45]],\n",
       "\n",
       "       [[ 35,  66,  27],\n",
       "        [ 35,  66,  27],\n",
       "        [ 35,  66,  27],\n",
       "        ...,\n",
       "        [ 41,  92,  42],\n",
       "        [ 41,  92,  42],\n",
       "        [ 42,  93,  43]],\n",
       "\n",
       "       [[ 36,  67,  28],\n",
       "        [ 37,  68,  29],\n",
       "        [ 37,  68,  29],\n",
       "        ...,\n",
       "        [ 42,  93,  43],\n",
       "        [ 42,  93,  43],\n",
       "        [ 42,  94,  41]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [ 50, 138,  72],\n",
       "        [ 47, 138,  69],\n",
       "        [ 47, 139,  68]],\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [ 48, 136,  70],\n",
       "        [ 48, 136,  70],\n",
       "        [ 48, 137,  68]],\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [ 48, 134,  70],\n",
       "        [ 48, 135,  69],\n",
       "        [ 48, 135,  69]]], dtype=uint8)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw and display contours \n",
    "cv2.drawContours(contour_images, contours, -1, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "19ffcc45-cbf2-45e1-8d70-16d3a2fa267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':contour_images})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fda68-de0b-46f4-867c-a7c63f08edd6",
   "metadata": {},
   "source": [
    "## Implement optical flow for motion analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8924c9c-5572-4d39-8f38-a98159f61958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Capture video feed \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Read the frame\n",
    "ret1, frame1 = cap.read()\n",
    "prev_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame2 = cap.read()\n",
    "    current_gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate optical flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, current_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    # Draw motion vectors\n",
    "    motion_image = np.copy(frame2)\n",
    "    for y in range(0, motion_image.shape[0], 10):\n",
    "        for x in range(0, motion_image.shape[1], 10):\n",
    "            dx, dy = flow[y, x]\n",
    "            cv2.arrowedLine(motion_image, (x, y), (int(x+dx), int(y+dy)), (0, 0, 255), 1)\n",
    "    \n",
    "    prev_gray = current_gray\n",
    "\n",
    "    # cv2.imshow('Video', frame1)\n",
    "    # cv2.imshow('Gray Video', prev_gray)\n",
    "    cv2.imshow('Optical Flow', motion_image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52b53ad-e250-42d1-bbf0-d75a58faaeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d392b35b-4106-4db0-8106-b9c29ee698a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 20:24:52.231 python3.10[45608:2906623] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 20:24:52.345 python3.10[45608:2906623] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 20:27:43.118 python3.10[45608:2906623] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 20:27:43.212 python3.10[45608:2906623] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 20:27:43.216 python3.10[45608:2906623] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 20:27:48.026 python3.10[45608:2906623] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 20:27:48.110 python3.10[45608:2906623] +[CATransaction synchronize] called within transaction\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/work/.pyenv/versions/3.10.9/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a Tinker GUI\n",
    "root = tk.Tk()\n",
    "root.title('Open CV Image Processing APP') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to open a image\n",
    "def oepn_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        display_image(image)\n",
    "\n",
    "# Function to display image\n",
    "def display_image(image):\n",
    "    pil_image = Image.fromarray(image)\n",
    "    tk_image = ImageTk.PhotoImage(image = pil_image)\n",
    "    label.config(image = tk_image)\n",
    "    label.image = tk_image\n",
    "\n",
    "\n",
    "# Create a button\n",
    "open_button = tk.Button(root, text = 'Open Image', command = oepn_image)\n",
    "\n",
    "# Create an Image display label \n",
    "label = tk.Label(root)\n",
    "label.pack()\n",
    "\n",
    "# Plaace the button\n",
    "open_button.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e118c4-a979-45e3-bba3-1a042e7b1429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 20:59:57.854 python3.10[67411:2982988] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 20:59:57.988 python3.10[67411:2982988] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 21:00:06.586 python3.10[67411:2982988] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 21:00:06.667 python3.10[67411:2982988] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 21:00:09.343 python3.10[67411:2982988] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 21:00:09.417 python3.10[67411:2982988] +[CATransaction synchronize] called within transaction\n"
     ]
    }
   ],
   "source": [
    "# from tkmacosx import Label\n",
    "\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    " \n",
    "\n",
    "#Create a Tinker GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"OpenCV Image Processing APP\")\n",
    "\n",
    " \n",
    "\n",
    "#Function to open a image\n",
    "def open_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        img = cv2.imread(file_path)\n",
    "        img_cvt = cv2.cvtColor(img , cv2.COLOR_BGR2RGB)\n",
    "        display_image(img_cvt)\n",
    "\n",
    " \n",
    "\n",
    "#Function to display image\n",
    "def display_image(image):\n",
    "    pil_image = Image.fromarray(image)\n",
    "    tk_image = ImageTk.PhotoImage(image = pil_image)\n",
    "    label.config(image = tk_image)\n",
    "    label.image = tk_image\n",
    "    label.pack()\n",
    "\n",
    "def convert_to_grayscale():\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "def edge_detect():\n",
    "    pass\n",
    "\n",
    "#Create a button \n",
    "open_button = tk.Button(root , text = \"Open Image\" , command = open_image)\n",
    "grayscale_button = tk.Button(root, text='Convert to grayScale', command=convert_to_grayscale)\n",
    "edge_button = tk.Button(root, text='Edge Detection', command=edge_detect)\n",
    "\n",
    "#Create an Image display label\n",
    "label = tk.Label(root)\n",
    "label.pack()\n",
    "\n",
    " \n",
    "\n",
    "#Place the button\n",
    "open_button.pack()\n",
    "grayscale_button.pack()\n",
    "edge_button.pack()\n",
    " \n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b677075-a14e-46b4-8056-6fd605e6cc72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005f358e-4150-421b-9889-31068434490b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9763b83d-e7a7-40d8-beea-8a8f7092e7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
