{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319d7569-c5d1-4477-b255-db416f7208dd",
   "metadata": {},
   "source": [
    "# Introduction to Computer Vision and OpenCV:\n",
    "\n",
    "Understand the fundamentals of computer vision and its applications.\n",
    "Learn the basics of the OpenCV library and its core functions.\n",
    "Setup your development environment with OpenCv\n",
    "Load and display images using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e309267-8895-4e66-b49c-2cdb71b51633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e04c9dab-5a2e-411f-9ed0-7d324da66bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/work/Desktop/ccp-cv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1359ca07-4bc1-4c8e-a6fc-da3f68fe0974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48763fc5-32e8-4e79-8232-cff390e79b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./cat.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50947836-0952-43c5-a30b-d29a0208cb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436fec87-80b3-4aa1-aa22-8c891e019b1c",
   "metadata": {},
   "source": [
    "# Image Processing Techniques using OpenCV:\n",
    "\n",
    "Implement basic image processing techniques such as resizing, cropping, and color manipulation.\n",
    "Apply various filters and enhancements to images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e26d721-7b82-4051-928e-ac7362d4692c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cord = 0\n",
    "y_cord = 0\n",
    "\n",
    "def mouse_callback(event, x, y, flats, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(img, (x,y), radius=3, color=(0, 0, 255), thickness=2)\n",
    "        cv2.putText(img, f'x:{x}', (x+10,y-10) , \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.5, \n",
    "                    (0,0,0), 2)\n",
    "        cv2.putText(img, f'y:{y}', (x+10,y+10) , \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    (0,0,0), 2)\n",
    "        cv2.imshow('Image', img)\n",
    "        print(f\"Coordinates: {x}, {y}\")\n",
    "\n",
    "# Create a window and set the mouse callback function\n",
    "cv2.namedWindow('Image')\n",
    "cv2.setMouseCallback('Image', mouse_callback)\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ab6b931-1a53-4249-93b2-3fbb8fd371db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(imgs):\n",
    "    for k, img in imgs.items():\n",
    "        cv2.imshow(k, img)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e2a9a80-2b33-4562-ba91-84ea3ed59056",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_face = img[18:356, 103:416]\n",
    "resized = cv2.resize(img, (100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6512853-8a60-4371-9688-81bc82fe5648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('img', resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "842ff086-d5d8-4914-8c5f-8cf9a113ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_img = cv2.GaussianBlur(img, (9,9), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9311e960-f61b-46f4-ba4d-3d24ff93ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af61cddc-5316-424a-977c-8399451a324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f81bbed1-349a-45f0-b071-513014bdc76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, otsu_thresholding = cv2.threshold(img_gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dac56bb3-9fd5-4925-9b56-d73fe3aea660",
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(img_gray,50,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57192c6f-8132-4ee1-a617-21718b5d45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "opening = cv2.morphologyEx(otsu_thresholding, cv2.MORPH_OPEN, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d20388ce-060f-4d4a-bf46-c8f82f6bdf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_img = 255 - img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9352cfe-a7e6-44ec-a4a1-835df4fabc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'opening':opening,\n",
    "          'otsu_thresholding':otsu_thresholding,\n",
    "          'Gaussian':blurred_img,\n",
    "          'invert':inverted_img})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7bcc8-f688-4095-9baa-1af0b125b298",
   "metadata": {},
   "source": [
    "# Object Detection and Tracking:\n",
    "\n",
    "Implement object detection using pre-trained deep learning models (e.g., YOLO or SSD).\n",
    "Develop real-time object tracking using techniques like the Kalman filter or Mean-Shift algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02cea03b-4ccb-491e-a8b5-1ac0a2f1a7b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'coco.names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m net \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mdnn\u001b[39m.\u001b[39mreadNet(\u001b[39m'\u001b[39m\u001b[39myolov3.weights\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39myolov3.cfg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m classes \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 11\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mcoco.names\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     12\u001b[0m     classes \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[39m# Create a Tkinter GUI\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'coco.names'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    " \n",
    "\n",
    "# Load YOLO model and COCO class names\n",
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
    "classes = []\n",
    "with open('coco.names', 'r') as f:\n",
    "    classes = f.read().strip().split('\\n')\n",
    "\n",
    " \n",
    "\n",
    "# Create a Tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title('YOLO Object Detection App')\n",
    "\n",
    " \n",
    "\n",
    "# Function to open an image using a file dialog\n",
    "def open_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        detect_objects(image)\n",
    "\n",
    " \n",
    "\n",
    "# Function to display an OpenCV image in the GUI\n",
    "def display_image(cv_image):\n",
    "    pil_image = Image.fromarray(cv_image)\n",
    "    tk_image = ImageTk.PhotoImage(image=pil_image)\n",
    "    label.config(image=tk_image)\n",
    "    label.image = tk_image\n",
    "\n",
    " \n",
    "\n",
    "# Function to perform object detection\n",
    "def detect_objects(cv_image):\n",
    "    height, width = cv_image.shape[:2]\n",
    "\n",
    " \n",
    "\n",
    "    # Prepare input image for YOLO model\n",
    "    blob = cv2.dnn.blobFromImage(cv_image, 1/255, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    " \n",
    "\n",
    "    # Get detection results\n",
    "    outs = net.forward(net.getUnconnectedOutLayersNames())\n",
    "\n",
    " \n",
    "\n",
    "    # Process detection results\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = scores.argmax()\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.7:  # Set a confidence threshold\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    " \n",
    "\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    " \n",
    "\n",
    "                # Draw bounding box and class label\n",
    "                cv2.rectangle(cv_image, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "                label = f'{classes[class_id]}: {confidence:.2f}'\n",
    "                cv2.putText(cv_image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    " \n",
    "\n",
    "    display_image(cv_image)\n",
    "\n",
    " \n",
    "\n",
    "# Create buttons for opening an image\n",
    "open_button = tk.Button(root, text=\"Open Image\", command=open_image)\n",
    "\n",
    " \n",
    "\n",
    "# Create an image display label\n",
    "label = tk.Label(root)\n",
    "label.pack()\n",
    "\n",
    " \n",
    "\n",
    "# Place buttons in the GUI\n",
    "open_button.pack()\n",
    "\n",
    " \n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78def8ed-9088-44e8-8eb1-8273d4515f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cv2.resize(img, (416,416))\n",
    "\n",
    "scalefactor = 1.0/255.0\n",
    "size = (416,416)\n",
    "mean = (0,0) # Mean values for image Normalisation\n",
    "swapRB = True # Swap red and blue channels for image preprocessing\n",
    "crop = False # Do not crop the image during blob creation\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(resized,\n",
    "                            scalefactor,\n",
    "                            size,\n",
    "                            mean,\n",
    "                            swapRB=swapRB,\n",
    "                            crop=crop)\n",
    "\n",
    "net.setInput(blob)\n",
    "output_layers = net.getUnconnectedOutLayersNames()\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "# tracker = cv2.TrackerKCF_create()\n",
    "tracker = cv2.legacy_TrackerMOSSE.create()\n",
    "\n",
    "bbox = cv2.selectROI(img, False)\n",
    "\n",
    "tracker.init(img, bbox)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be07e5f-391c-42c5-8926-68487c46abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b593d5e2-c763-4739-b318-1f4d2db4f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':resized})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4874a0d9-04a2-427a-9f3c-b6d1ad6deeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b6a440-4df8-4b37-af98-e1aa62788ed7",
   "metadata": {},
   "source": [
    "# Feature Detection and Matching:\n",
    "\n",
    "Explore feature detection methods such as SIFT or ORB.\n",
    "Implement feature matching to establish correspondence between images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff335229-899e-4014-9227-f414f20ea2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread('./cat.jpg')\n",
    "img2 = cv2.imread('./cat2.jpg')\n",
    "\n",
    "# Create a ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Find key Points and descriptors\n",
    "keypoints1, descriptors1 = orb.detectAndCompute(img1, None)\n",
    "keypoints2, descriptors2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "# Initialize Brute force matcher\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# Match Descriptors \n",
    "matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "matching_results = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches[:30], None, flags=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9768ea80-92d2-4eff-a5c0-68b0c740c92b",
   "metadata": {},
   "source": [
    "* im1 - The source image\n",
    "* keypoints1 - list of key points detected in the first image\n",
    "* im2 - second image where matches will be viualized\n",
    "* keypoints2 - List of keypoints detected in second image\n",
    "* matches[:20] - a subset of matches to be draw\n",
    "* None - Optional mask image, if provided, only the key points that are within the mask will be used in the matching visualisation \n",
    "* flats = 2 - the flag that specifies how to draw the matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0feef99c-f2ed-4bc2-95e3-c8f05ce898b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':matching_results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "071221b9-0815-4b3b-8658-3d031583e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':descriptors2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677148e3-9ef4-4c2e-9773-0a6cf0fc3526",
   "metadata": {},
   "source": [
    "# Activity 5: Image Filtering and Transformation:\n",
    "\n",
    " Apply advanced image filtering techniques, such as Gaussian blur and edge detection.\n",
    " Explore geometric transformations like rotation, scaling, and perspective transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fc7e7cd-b353-4752-9688-aee1596fb4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = cv2.GaussianBlur(img1, (11,11), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be147f6f-e65e-4305-8be1-72ad2234636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb2934fa-229f-40ba-8218-b04c3499149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(gray,100,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "feccdc09-ef2b-4fea-9b3d-03a8d53a9883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation\n",
    "angle = 30\n",
    "rows, cols = img1.shape[:2]\n",
    "rotation_matrix = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
    "rotated_matrix = cv2.warpAffine(img1, rotation_matrix, (cols, rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbc0244a-31b4-4da3-812d-ca163849cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':gaussian,\n",
    "          'cann':edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c3cd12a-643c-4f65-a788-ffcb839a5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':rotated_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92df741c-4e9f-435a-9b29-362c1955d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = 0.5\n",
    "scaled = cv2.resize(img1, None, fx=scale_factor, fy=scale_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c865097e-425a-4b22-b27b-91c287f0b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':scaled})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "040c5d46-8505-4cd4-b2b9-5b6c6616a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspective transformation\n",
    "pts1 = np.float32([[50,50], [200,50], [50, 200], [200, 200]])\n",
    "pts2 = np.float32([[0,0], [250,0], [0, 250], [250, 250]])\n",
    "\n",
    "perspective_matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "perspective_transformed = cv2.warpPerspective(img1, perspective_matrix, (250,250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f1ebf3b4-fe3c-455b-ae15-d4c8090a183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':perspective_transformed})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4361ff-2081-4cb5-a025-f67360a4848c",
   "metadata": {},
   "source": [
    "# Activity 6: Advanced Computer Vision Techniques:\n",
    " Dive into advanced techniques like image segmentation and contour detection.\n",
    "\n",
    " Implement optical flow for motion analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9198f26a-84a1-4be0-bab8-7f0f4a887c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('cat.jpg', )\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a015f64-67ee-4d72-bc6e-4b844f455fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(gray, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4b2cd483-c3fb-47af-ad4f-b3f810c7e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "453320e9-5934-4076-98a8-131c1299dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_images = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bbb289aa-4b50-4c12-a3af-0bead156b8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 39,  69,  34],\n",
       "        [ 38,  69,  32],\n",
       "        [ 37,  68,  31],\n",
       "        ...,\n",
       "        [ 39,  90,  40],\n",
       "        [ 41,  91,  43],\n",
       "        [ 43,  93,  45]],\n",
       "\n",
       "       [[ 35,  66,  27],\n",
       "        [ 35,  66,  27],\n",
       "        [ 35,  66,  27],\n",
       "        ...,\n",
       "        [ 41,  92,  42],\n",
       "        [ 41,  92,  42],\n",
       "        [ 42,  93,  43]],\n",
       "\n",
       "       [[ 36,  67,  28],\n",
       "        [ 37,  68,  29],\n",
       "        [ 37,  68,  29],\n",
       "        ...,\n",
       "        [ 42,  93,  43],\n",
       "        [ 42,  93,  43],\n",
       "        [ 42,  94,  41]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [ 50, 138,  72],\n",
       "        [ 47, 138,  69],\n",
       "        [ 47, 139,  68]],\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [ 48, 136,  70],\n",
       "        [ 48, 136,  70],\n",
       "        [ 48, 137,  68]],\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [ 48, 134,  70],\n",
       "        [ 48, 135,  69],\n",
       "        [ 48, 135,  69]]], dtype=uint8)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw and display contours \n",
    "cv2.drawContours(contour_images, contours, -1, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "19ffcc45-cbf2-45e1-8d70-16d3a2fa267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img({'':contour_images})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fda68-de0b-46f4-867c-a7c63f08edd6",
   "metadata": {},
   "source": [
    "## Implement optical flow for motion analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8924c9c-5572-4d39-8f38-a98159f61958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Capture video feed \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Read the frame\n",
    "ret1, frame1 = cap.read()\n",
    "prev_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame2 = cap.read()\n",
    "    current_gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate optical flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, current_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    # Draw motion vectors\n",
    "    motion_image = np.copy(frame2)\n",
    "    for y in range(0, motion_image.shape[0], 10):\n",
    "        for x in range(0, motion_image.shape[1], 10):\n",
    "            dx, dy = flow[y, x]\n",
    "            cv2.arrowedLine(motion_image, (x, y), (int(x+dx), int(y+dy)), (0, 0, 255), 1)\n",
    "    \n",
    "    prev_gray = current_gray\n",
    "\n",
    "    # cv2.imshow('Video', frame1)\n",
    "    # cv2.imshow('Gray Video', prev_gray)\n",
    "    cv2.imshow('Optical Flow', motion_image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52b53ad-e250-42d1-bbf0-d75a58faaeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d392b35b-4106-4db0-8106-b9c29ee698a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 20:24:52.231 python3.10[45608:2906623] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 20:24:52.345 python3.10[45608:2906623] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 20:27:43.118 python3.10[45608:2906623] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 20:27:43.212 python3.10[45608:2906623] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 20:27:43.216 python3.10[45608:2906623] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 20:27:48.026 python3.10[45608:2906623] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 20:27:48.110 python3.10[45608:2906623] +[CATransaction synchronize] called within transaction\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/work/.pyenv/versions/3.10.9/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a Tinker GUI\n",
    "root = tk.Tk()\n",
    "root.title('Open CV Image Processing APP') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to open a image\n",
    "def oepn_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        display_image(image)\n",
    "\n",
    "# Function to display image\n",
    "def display_image(image):\n",
    "    pil_image = Image.fromarray(image)\n",
    "    tk_image = ImageTk.PhotoImage(image = pil_image)\n",
    "    label.config(image = tk_image)\n",
    "    label.image = tk_image\n",
    "\n",
    "\n",
    "# Create a button\n",
    "open_button = tk.Button(root, text = 'Open Image', command = oepn_image)\n",
    "\n",
    "# Create an Image display label \n",
    "label = tk.Label(root)\n",
    "label.pack()\n",
    "\n",
    "# Plaace the button\n",
    "open_button.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e118c4-a979-45e3-bba3-1a042e7b1429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 21:27:46.383 python[69394:3011543] +[CATransaction synchronize] called within transaction\n",
      "2023-08-21 21:27:46.529 python[69394:3011543] +[CATransaction synchronize] called within transaction\n"
     ]
    }
   ],
   "source": [
    "# from tkmacosx import Label\n",
    "\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    " \n",
    "\n",
    "#Create a Tinker GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"OpenCV Image Processing APP\")\n",
    "\n",
    " \n",
    "\n",
    "#Function to open a image\n",
    "def open_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        img = cv2.imread(file_path)\n",
    "        img_cvt = cv2.cvtColor(img , cv2.COLOR_BGR2RGB)\n",
    "        display_image(img_cvt)\n",
    "\n",
    " \n",
    "\n",
    "#Function to display image\n",
    "def display_image(image):\n",
    "    pil_image = Image.fromarray(image)\n",
    "    tk_image = ImageTk.PhotoImage(image = pil_image)\n",
    "    label.config(image = tk_image)\n",
    "    label.image = tk_image\n",
    "    label.pack()\n",
    "\n",
    "def convert_to_grayscale():\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "def edge_detect():\n",
    "    pass\n",
    "\n",
    "#Create a button \n",
    "open_button = tk.Button(root , text = \"Open Image\" , command = open_image)\n",
    "grayscale_button = tk.Button(root, text='Convert to grayScale', command=convert_to_grayscale)\n",
    "edge_button = tk.Button(root, text='Edge Detection', command=edge_detect)\n",
    "\n",
    "#Create an Image display label\n",
    "label = tk.Label(root)\n",
    "label.pack()\n",
    "\n",
    " \n",
    "\n",
    "#Place the button\n",
    "open_button.pack()\n",
    "grayscale_button.pack()\n",
    "edge_button.pack()\n",
    " \n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b677075-a14e-46b4-8056-6fd605e6cc72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005f358e-4150-421b-9889-31068434490b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9763b83d-e7a7-40d8-beea-8a8f7092e7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "53e599ddd7baeda3c6ce68be6a8a9256074f683aa4dcba1e13fad58798aaebb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
