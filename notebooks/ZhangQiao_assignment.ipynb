{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b10bf93c-2a8b-4dff-9bef-76f770664828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wx\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import imutils\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2422884f-fdbd-4cac-9c75-11c564c140ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 16:04:21.091 python3.10[32115:2268554] +[CATransaction synchronize] called within transaction\n",
      "2023-08-24 16:04:21.164 python3.10[32115:2268554] +[CATransaction synchronize] called within transaction\n",
      "2023-08-24 16:04:34.769 python3.10[32115:2268554] +[CATransaction synchronize] called within transaction\n",
      "2023-08-24 16:04:34.825 python3.10[32115:2268554] +[CATransaction synchronize] called within transaction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Frame(wx.Frame):\n",
    "    def __init__(self, parent, ID=-1, title=\"CCP CV Assignment\"):\n",
    "        super().__init__(parent, ID, title)\n",
    "\n",
    "        # Main window holds all the content\n",
    "        self.main_window = wx.FlexGridSizer(rows=2, cols=1, hgap=10, vgap=10)\n",
    "\n",
    "        # Contraollers holds all buttons and controls\n",
    "        self.controllers = wx.FlexGridSizer(rows=4, cols=4, hgap=2, vgap=2)\n",
    "\n",
    "        # Image Viewer\n",
    "        self.img_viewer = wx.StaticBitmap(self)\n",
    "        \n",
    "        # Add image viewer and controllers to main window\n",
    "        self.main_window.Add(self.img_viewer,0,0)\n",
    "        self.main_window.Add(self.controllers,0,0)\n",
    "        \n",
    "        self.img_viewer.SetMinSize((500,500))\n",
    "        self.controllers.SetMinSize((500,200))\n",
    "\n",
    "        # Controller Buttons\n",
    "        btn_load_img = wx.Button(self, label='Load Image')\n",
    "        btn_load_img.Bind(wx.EVT_BUTTON, self.OnBrowse)\n",
    "\n",
    "        btn_reset = wx.Button(self, label='Reset Image')\n",
    "        btn_reset.Bind(wx.EVT_BUTTON, self.OnReset)\n",
    "\n",
    "        btn_resize = wx.Button(self, label='Fit Image')\n",
    "        btn_resize.Bind(wx.EVT_BUTTON, \n",
    "                        lambda event:self.OnResize(event,width=500))\n",
    "\n",
    "        btn_crop = wx.Button(self, label='Crop 100')\n",
    "        btn_crop.Bind(wx.EVT_BUTTON, self.OnCrop)\n",
    "\n",
    "        btn_to_bw = wx.Button(self, label='B & W')\n",
    "        btn_to_bw.Bind(wx.EVT_BUTTON, self.OnGray)\n",
    "\n",
    "        btn_blur = wx.Button(self, label='Blur')\n",
    "        btn_blur.Bind(wx.EVT_BUTTON, self.OnBlur)\n",
    "\n",
    "        btn_edge = wx.Button(self, label='Detect Edge')\n",
    "        btn_edge.Bind(wx.EVT_BUTTON, self.OnDetectEdge)\n",
    "\n",
    "        btn_invert = wx.Button(self, label='Invert')\n",
    "        btn_invert.Bind(wx.EVT_BUTTON, self.OnInvert)\n",
    "\n",
    "        btn_detection = wx.Button(self, label='Detect Objects')\n",
    "        btn_detection.Bind(wx.EVT_BUTTON, self.OnDetect)\n",
    "\n",
    "        btn_on_cam = wx.Button(self, label='Turn On Camera')\n",
    "        btn_on_cam.Bind(wx.EVT_BUTTON, self.OnCam)\n",
    "\n",
    "        btn_release_cam = wx.Button(self, label='Release Camera')\n",
    "        btn_release_cam.Bind(wx.EVT_BUTTON, self.OnCapture)\n",
    "\n",
    "        btn_rotate = wx.Button(self, label='Rotate 10')\n",
    "        btn_rotate.Bind(wx.EVT_BUTTON, self.OnRotate)\n",
    "\n",
    "        btn_contour = wx.Button(self, label='Detect Contour')\n",
    "        btn_contour.Bind(wx.EVT_BUTTON, self.OnContour)\n",
    "\n",
    "        self.controllers.Add(btn_load_img, 0, 0)\n",
    "        self.controllers.Add(btn_reset, 0, 0)\n",
    "        self.controllers.Add(btn_resize, 0, 0)\n",
    "        self.controllers.Add(btn_crop, 0, 0)\n",
    "        self.controllers.Add(btn_to_bw, 0, 0)\n",
    "        self.controllers.Add(btn_blur, 0, 0)\n",
    "        self.controllers.Add(btn_edge, 0, 0)\n",
    "        self.controllers.Add(btn_invert, 0, 0)\n",
    "        self.controllers.Add(btn_detection, 0, 0)\n",
    "        self.controllers.Add(btn_on_cam, 0, 0)\n",
    "        self.controllers.Add(btn_release_cam, 0, 0)\n",
    "        self.controllers.Add(btn_rotate, 0, 0)\n",
    "        self.controllers.Add(btn_contour, 0, 0)\n",
    "        \n",
    "        self.SetSizer(self.main_window)\n",
    "        self.Fit()\n",
    "        \n",
    "        self.InitYolo()\n",
    "\n",
    "    def InitYolo(self):\n",
    "        # Load YOLO model and COCO class names\n",
    "        self.net = cv2.dnn.readNet('../yolov3/yolov3.weights', '../yolov3/yolov3.cfg')\n",
    "        self.classes = []\n",
    "        with open('../yolov3/coco.names', 'r') as f:\n",
    "            self.classes = f.read().strip().split('\\n')\n",
    "\n",
    "    def OnDetect(self, event):\n",
    "        # Prepare input image for YOLO model\n",
    "        img = self.img_raw\n",
    "\n",
    "        height, width = img.shape[:2]\n",
    "\n",
    "        # img = img.astype(np.float32)\n",
    "        \n",
    "        blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), swapRB=True, crop=False)\n",
    "        self.net.setInput(blob)\n",
    "        \n",
    "        # Get detection results\n",
    "        outs = self.net.forward(self.net.getUnconnectedOutLayersNames())\n",
    "\n",
    "        # Process detection results\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = scores.argmax()\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.7:  # Set a confidence threshold\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    # Draw bounding box and class label\n",
    "                    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "                    label = f'{self.classes[class_id]}: {confidence:.2f}'\n",
    "                    cv2.putText(img, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 1)\n",
    "\n",
    "        self.ShowCV2Image(img)\n",
    "\n",
    "    def OnContour(self, event):\n",
    "        img = self.GetCurrentImage()\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #Gaussian Blur\n",
    "        blurred_image = cv2.GaussianBlur(img , (5,5) , 0)\n",
    "    \n",
    "        #Canny\n",
    "        edges = cv2.Canny(img , 100 ,200)\n",
    "\n",
    "        #Identify contours in edge detected images\n",
    "        contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        #print(contours)\n",
    "\n",
    "        #Create a copy of the original image for drawing contours\n",
    "        contour_image = img.copy()\n",
    "\n",
    "        #Draw and display contours\n",
    "        cv2.drawContours(contour_image , contours , -1 , (0,255,0) , 2)\n",
    "        self.ShowCV2Image(contour_image)\n",
    "\n",
    "    def OnBrowse(self, event):\n",
    "        wildcard = 'PNG files (*.png)|*.png|BMP files (*.bmp)|*.bmp|JPEG files (*.jpg)|*.jpg|JPEG files (*.jpeg)|*.jpeg'\n",
    "        openFileDialog = wx.FileDialog(self, \"Open\", \"\", \"\", wildcard,\n",
    "                                       wx.FD_OPEN | wx.FD_FILE_MUST_EXIST)\n",
    "        openFileDialog.ShowModal()\n",
    "\n",
    "        # Use cv2 to open image\n",
    "        file_path = openFileDialog.GetPath()\n",
    "        img = cv2.imread(file_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        self.img_raw = img        \n",
    "\n",
    "        self.ShowCV2Image(img)\n",
    "\n",
    "    def OnResize(self, event, width=500):\n",
    "        img = self.GetCurrentImage()\n",
    "        # resized_img = imutils.resize(img, width=width)\n",
    "        or_width = img.shape[1]\n",
    "        or_height = img.shape[0]\n",
    "        ratio = width / or_width\n",
    "        height = int(or_height*ratio)\n",
    "        \n",
    "        resized_img = cv2.resize(img, (width, height))\n",
    "        \n",
    "        self.ShowCV2Image(resized_img)\n",
    "\n",
    "    def OnCrop(self, event,x=0,y=0,w=100,h=100):\n",
    "        '''\n",
    "        Crop a 100 by 100-pixel image\n",
    "        '''\n",
    "        img = self.GetCurrentImage()\n",
    "        cropped_img = img[y:y+h, x:x+w]\n",
    "        self.ShowCV2Image(cropped_img)\n",
    "\n",
    "    def OnReset(self, event):\n",
    "        img = self.img_raw\n",
    "        self.ShowCV2Image(img)\n",
    "\n",
    "    def OnBlur(self, event):\n",
    "        img = self.GetCurrentImage()\n",
    "        img_blur = cv2.GaussianBlur(img, (21,21), 0)\n",
    "        self.ShowCV2Image(img_blur)\n",
    "\n",
    "    def OnGray(self, event):\n",
    "        img = self.GetCurrentImage()\n",
    "        gray_image = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        self.ShowCV2Image(gray_image)\n",
    "\n",
    "    def OnDetectEdge(self, event):\n",
    "        img = self.GetCurrentImage()\n",
    "        edge = cv2.Canny(img, 100, 200)\n",
    "        self.ShowCV2Image(edge)\n",
    "\n",
    "    def OnInvert(self, event):\n",
    "        img = self.GetCurrentImage()\n",
    "        inverted = 255 - img\n",
    "        self.ShowCV2Image(inverted)\n",
    "\n",
    "    def OnCam(self, event):\n",
    "        self.release_cap = False\n",
    "        \n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        # Read the frame\n",
    "        ret1, frame1 = self.cap.read()\n",
    "        prev_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        n = 0\n",
    "        while n < 30:\n",
    "            time.sleep(1)\n",
    "            ret, frame2 = self.cap.read()\n",
    "            current_gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Calculate optical flow\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, current_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "            # Draw motion vectors\n",
    "            motion_image = np.copy(frame2)\n",
    "            for y in range(0, motion_image.shape[0], 10):\n",
    "                for x in range(0, motion_image.shape[1], 10):\n",
    "                    dx, dy = flow[y, x]\n",
    "                    cv2.arrowedLine(motion_image, (x, y), (int(x+dx), int(y+dy)), (0, 0, 255), 1)\n",
    "    \n",
    "            prev_gray = current_gray\n",
    "\n",
    "            print('Dwaing image')\n",
    "\n",
    "            # self.ShowCV2Image(motion_image)\n",
    "            cv2.imshow('Optical Flow', motion_image)\n",
    "            \n",
    "            # self.release_cap = True\n",
    "            n = n + 1\n",
    "            \n",
    "\n",
    "            if self.release_cap:\n",
    "                self.cap.release()\n",
    "                self.release_cap = False\n",
    "                cv2.destroyAllWindows()\n",
    "                cv2.waitKey(1)\n",
    "                break\n",
    "\n",
    "    def OnRotate(self, event):\n",
    "        img = self.GetCurrentImage()\n",
    "        #Rotation\n",
    "        angle = 10\n",
    "        rows,cols = img.shape[:2]\n",
    "        rotation_matrix = cv2.getRotationMatrix2D((cols/2 , rows/2) , angle , 1)\n",
    "        rotated_matrix = cv2.warpAffine(img , rotation_matrix , (cols,rows))\n",
    "        self.ShowCV2Image(rotated_matrix)\n",
    "                \n",
    "    def OnCapture(self, event):\n",
    "        self.release_cap = True\n",
    "\n",
    "    def GetCurrentImage(self):\n",
    "        '''\n",
    "        Get the current displaying image, and return as a cv image object\n",
    "        '''\n",
    "        img = self.img_viewer.GetBitmap().ConvertToImage()\n",
    "        img_buffer = img.GetDataBuffer()\n",
    "        \n",
    "        pil_img = Image.frombuffer('RGB', (img.Width, img.Height), img_buffer)\n",
    "        arr_img = np.array(pil_img)\n",
    "\n",
    "        cv_img = cv2.cvtColor(arr_img, None)\n",
    "        return cv_img\n",
    "\n",
    "    \n",
    "    def ShowCV2Image(self, img):\n",
    "        '''\n",
    "        Display a cv2 image object\n",
    "        img: cv2 image object\n",
    "        '''\n",
    "        img_container = wx.Image(img.shape[1], img.shape[0])\n",
    "        pil_img = Image.fromarray(img)\n",
    "        img_container.SetData(pil_img.convert(\"RGB\").tobytes())\n",
    "        \n",
    "        bmp_img = wx.Bitmap(img_container)\n",
    "        self.img_viewer.SetBitmap(bmp_img)\n",
    "\n",
    "app = wx.App()\n",
    "frame = Frame(None)\n",
    "frame.Show()\n",
    "app.MainLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7de71c9e-5ece-4d8f-8828-8fa1f6f40ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Capture video feed \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Read the frame\n",
    "ret1, frame1 = cap.read()\n",
    "prev_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame2 = cap.read()\n",
    "    current_gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate optical flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, current_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    # Draw motion vectors\n",
    "    motion_image = np.copy(frame2)\n",
    "    for y in range(0, motion_image.shape[0], 10):\n",
    "        for x in range(0, motion_image.shape[1], 10):\n",
    "            dx, dy = flow[y, x]\n",
    "            cv2.arrowedLine(motion_image, (x, y), (int(x+dx), int(y+dy)), (0, 0, 255), 1)\n",
    "    \n",
    "    prev_gray = current_gray\n",
    "\n",
    "    # cv2.imshow('Video', frame1)\n",
    "    # cv2.imshow('Gray Video', prev_gray)\n",
    "    cv2.imshow('Optical Flow', motion_image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a460c504-92f1-4c1d-85f3-f7edd06472cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
